# -*- coding: utf-8 -*-
"""rdret.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IOoHUkIUd25q0pcUWz4yIwolgsJ3o53R
"""

# ==========================================
# Streamlit Multi-Agent DQN ET Jamming Dashboard
# ==========================================

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.animation import FuncAnimation
from io import BytesIO
import time

# PettingZoo ortam ve DQN ajanlarını buraya import et
# from your_dqn_module import RealisticJammingEnv, DQNAgent
import numpy as np
from pettingzoo import AECEnv
from pettingzoo.utils.agent_selector import AgentSelector
from gymnasium import spaces

class RealisticJammingEnv(AECEnv):
    def __init__(self, n_jammers=2, n_radars=1, max_power=10, n_freq=5):
        super().__init__()
        self.n_jammers = n_jammers
        self.n_radars = n_radars
        self.agents = ["jammer_" + str(i) for i in range(n_jammers)] + ["radar_" + str(i) for i in range(n_radars)]
        self.possible_agents = self.agents[:]
        self.max_power = max_power
        self.n_freq = n_freq

        # Her ajan için action space: power x freq kombinasyonu
        self.action_spaces = {agent: spaces.Discrete(max_power * n_freq) for agent in self.agents}
        self.observation_spaces = {agent: spaces.Box(low=0, high=max_power, shape=(3,), dtype=np.float32)
                                   for agent in self.agents}

    def reset(self, seed=None, options=None):
        # State: [current_power, current_freq, SNR_or_detection_metric]
        self.state = {agent: np.array([0.0, np.random.randint(self.n_freq), np.random.rand()*5], dtype=np.float32) 
                      for agent in self.agents}
        self.agent_selection = AgentSelector(self.agents)
        self._cumulative_rewards = {agent: 0 for agent in self.agents}
        self.dones = {agent: False for agent in self.agents}
        self.infos = {agent:{} for agent in self.agents}
        return self.state

    def observe(self, agent):
        return self.state[agent]

    def step(self, action_dict):
        rewards = {}
        for agent, action in action_dict.items():
            power = action // self.n_freq
            freq = action % self.n_freq

            self.state[agent] = np.array([power, freq, self.state[agent][2]], dtype=np.float32)

            reward = 0
            if "jammer" in agent:
                # Jammer radarın SNR'ını düşürür
                for r in [a for a in self.agents if "radar" in a]:
                    if freq == int(self.state[r][1]):
                        self.state[r][2] = max(0, self.state[r][2] - 0.1*power)
                reward = np.sum([5 - self.state[r][2] for r in self.agents if "radar" in r])
            else:
                # Radar ödülü kendi SNR'ı
                reward = self.state[agent][2]

            self._cumulative_rewards[agent] += reward
            rewards[agent] = reward
        return self.state, rewards

# -------------------------------
# Streamlit Başlık
# -------------------------------
st.set_page_config(page_title="Multi-Agent ET Jamming", layout="wide")
st.title("Multi-Agent DQN ET Jamming Simulation")

# -------------------------------
# Eğitim Parametreleri
# -------------------------------
n_episodes = st.sidebar.slider("Number of Episodes", 50, 500, 200, 25)
n_jammers = st.sidebar.slider("Number of Jammers", 1, 5, 2)
n_radars = st.sidebar.slider("Number of Radars", 1, 3, 1)
max_power = st.sidebar.slider("Max Jammer Power", 1, 20, 10)
n_freq = st.sidebar.slider("Number of Frequencies", 2, 10, 5)

st.sidebar.write("Click 'Start Simulation' to run.")
start_button = st.sidebar.button("Start Simulation")

# -------------------------------
# Başlatma
# -------------------------------
if start_button:
    env = RealisticJammingEnv(n_jammers=n_jammers, n_radars=n_radars, max_power=max_power, n_freq=n_freq)
    agents = {agent: DQNAgent(obs_size=3, n_actions=env.action_spaces[agent].n) for agent in env.agents}

    snr_baseline = 5.0
    snr_history = {r: [] for r in env.agents if "radar" in r}
    jammer_freq_history = {j: [] for j in env.agents if "jammer" in j}
    detection_scores = {r: [] for r in snr_history}
    jamming_impact_scores = []
    state_history = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for ep in range(n_episodes):
        state = env.reset()
        action_dict = {agent: agents[agent].act(state[agent]) for agent in env.agents}
        next_state, rewards = env.step(action_dict)

        # Hafızaya ekle ve replay
        for agent in env.agents:
            agents[agent].remember(state[agent], action_dict[agent], rewards[agent], next_state[agent])
            agents[agent].replay()

        state_history.append(next_state)
        for r in snr_history:
            snr = next_state[r][2]
            snr_history[r].append(snr)
            detection_scores[r].append(snr / snr_baseline)
        for j in jammer_freq_history:
            jammer_freq_history[j].append(int(next_state[j][1]))

        jamming_impact = np.mean([snr_baseline - next_state[r][2] for r in snr_history])
        jamming_impact_scores.append(jamming_impact)

        progress_bar.progress((ep + 1)/n_episodes)
        status_text.text(f"Episode {ep+1}/{n_episodes}: Avg Jamming Impact = {jamming_impact:.2f}")
        time.sleep(0.01)  # küçük bekleme, UI güncellemesi için

    st.success("Simulation Complete!")

    # -------------------------------
    # Dashboard Grafikleri
    # -------------------------------
    fig, axes = plt.subplots(2,2, figsize=(14,10))
    radars = list(snr_history.keys())
    jammers = list(jammer_freq_history.keys())
    n_iterations = len(state_history)

    # Son durumu görselleştirme
    state = state_history[-1]

    # Radar SNR Bar Grafiği
    axes[0,0].bar(radars, [state[r][2] for r in radars], color='skyblue')
    axes[0,0].set_ylim(0,5)
    axes[0,0].set_title("Radar SNR at Final Episode")

    # Radar Detection Score Zaman Serisi
    for r in radars:
        axes[0,1].plot(detection_scores[r], label=r)
    axes[0,1].set_xlabel("Episode")
    axes[0,1].set_ylabel("Detection Score")
    axes[0,1].set_title("Radar Detection Score")
    axes[0,1].legend()

    # Jammer Frekans Heatmap
    jammer_matrix = np.array([jammer_freq_history[j] for j in jammers])
    sns.heatmap(jammer_matrix, annot=False, fmt="d", cmap="YlOrRd", cbar=True, ax=axes[1,0])
    axes[1,0].set_xlabel("Episode")
    axes[1,0].set_ylabel("Jammer Agents")
    axes[1,0].set_title("Jammer Frequency Choices")

    # Jammer Impact Score Zaman Serisi
    axes[1,1].plot(jamming_impact_scores, color='red', label='Jamming Impact')
    axes[1,1].set_xlabel("Episode")
    axes[1,1].set_ylabel("Average SNR Reduction")
    axes[1,1].set_title("Jammer Impact Score")
    axes[1,1].legend()

    plt.tight_layout()
    st.pyplot(fig)
